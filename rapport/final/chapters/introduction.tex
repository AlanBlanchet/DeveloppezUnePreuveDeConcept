\section{Introduction}

Le monde du Reinforcement Learning (RL) se rapproche de plus en plus de celui du Machine Learning (ML). De plus en plus d'approches utilisent des réseaux classiques tels que le \ucite{ResNet} dans des algorithmes d'état de l'art comme \ucite{IMPALA}. Réseaux de RL qui malgré son âge a pourtant toujours autant d'importance dans le domaine.

En RL, des recherches sont faites pour trouver des algorithmes qui permettent d'atteindre des objectifs de plus en plus complexes. Ces algorithmes se retrouvent toujours face à une problématique cruciale : 'Exploration vs Exploitation'.

~\\
Ce rapport a pour but de présenter l'algorithme 'Never Give Up' \ucite{NGU} qui possède également des similarités avec le domain du ML. Il s'appuie sur une technique de récompense extrinsèque et intrinsèque pour maximiser l'exploration dans certains cas et la minimiser dans d'autres comme par exemple pour des observations redondantes ou des observations inutiles.